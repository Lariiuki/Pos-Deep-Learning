## Explica√ß√£o do Projeto üîé

Grupo: Larissa Akemi Iuki, Marcos Vinicuis Suguino, Ana Vit√≥ria da Silva Santos, Luan Fernandes de Fran√ßa, Vinicius da Silva Ferreira Lima

**Objetivo:** O trabalho consiste em projetar e implementar uma rede neural artificial a partir do exemplo exemplo4.py.
Foram feitas modifica√ß√µes na arquitetura, nas fun√ß√µes de ativa√ß√£o e na base de dados para observar como esses fatores influenciam o desempenho do modelo. No notebook, foi realizado um experimento de classifica√ß√£o utilizando redes neurais para separar dados n√£o linearmente separ√°veis, gerados pela fun√ß√£o make_circles do scikit-learn. 

## C√≥digo exemplo

C√≥digo original (exemplo4.py) utilizava o dataset 'make_moons', implementava uma rede neural manual com 1 camada escondida com 2 neur√¥nios, com fun√ß√£o de ativa√ß√£o **Sigmoide** e algoritmo de retropropaga√ß√£o + gradiente descendente. Tamb√©m implementava uma vers√£o em Keras, como compara√ß√£o.

## C√≥digo modificado

As modifica√ß√µes realizadas foi a mudan√ßa do dataset utilizado para 'make_circles', que gera pontos em c√≠rculos conc√™ntricos, com ru√≠do, para simular um problema de classifica√ß√£o bin√°ria. Na rede manual aumentamos a camada escondida de 2 para 4 neur√¥nios e a fun√ß√£o de ativa√ß√£o que utilizamos √© a **tanh**. Na rede com keras definimos 2 camadas escondidas de 8 neur√¥nios cada, com fun√ß√£o de ativa√ß√£o **ReLU** e com camada de sa√≠da **Sigmoide**. O treinamento foi feito via gradiente descendente, ajustando os pesos para minimizar o erro quadr√°tico. A acur√°cia da rede foi avaliada antes e depois do treinamento, mostrando a evolu√ß√£o do aprendizado. O modelo final apresentou uma acur√°cia significativamente melhor, mostrando que as modifica√ß√µes na arquitetura e nas fun√ß√µes de ativa√ß√£o tiveram impacto positivo.

## Conclus√£o

No in√≠cio do treinamento, a perda era muito alta, com valor de `0 [14.72242375]`. √Ä medida que o modelo √© treinado, a perda diminui progressivamente, atingindo `0.26997605` ap√≥s 4.000 itera√ß√µes. Esse comportamento indica que o modelo est√° aprendendo, pois a fun√ß√£o de perda apresenta uma tend√™ncia clara de decrescimento.

A acur√°cia final alcan√ßou 100%, o que significa que o modelo classificou **todas as amostras corretamente**. Al√©m disso, a perda final √© extremamente baixa (`0.0147`), confirmando que as previs√µes do modelo est√£o muito pr√≥ximas dos valores reais.
